{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import trange, tqdm\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data.dataloader as loader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from train_dataset import DataServoStereo\n",
    "import train_model as model\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on GPU or CPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU\n"
     ]
    }
   ],
   "source": [
    "with open(\"cfg/train_real_images.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "gpu_enabled = config[\"gpu\"]\n",
    "\n",
    "if gpu_enabled:\n",
    "    print(\"Training on GPU\")\n",
    "else:\n",
    "    print(\"Training on CPU\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = yaml.load(open(\"cfg/train_real_images.yaml\", 'r'), yaml.Loader)\n",
    "arg = namedtuple('Arg', arg.keys())(**arg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpu_enabled == True:\n",
    "    cudnn.enabled = True\n",
    "    cudnn.benchmark = True\n",
    "    cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kper = model.KeyPointGaussian(arg.sigma_kp[0], (arg.num_keypoint, *arg.im_size[1]))\n",
    "if gpu_enabled ==True:\n",
    "    enc = model.Encoder(arg.num_input, arg.num_keypoint, arg.growth_rate[0], arg.blk_cfg_enc, arg.drop_rate, kper).cuda()\n",
    "else:   \n",
    "    enc = model.Encoder(arg.num_input, arg.num_keypoint, arg.growth_rate[0], arg.blk_cfg_enc, arg.drop_rate, kper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam([{'params': enc.parameters(),\n",
    "                           'weight_decay': arg.wd[0]}],\n",
    "                         lr=arg.lr, amsgrad=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to adjust the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lr(ep, ep_train, bn=True):\n",
    "    # Check the value of the argument lr_anne and set the learning rate accordingly\n",
    "    if arg.lr_anne == 'step':\n",
    "        # Use a step function to adjust the learning rate\n",
    "        a_lr = 0.4 ** ((ep > (0.3 * ep_train)) +\n",
    "                       (ep > (0.6 * ep_train)) +\n",
    "                       (ep > (0.9 * ep_train)))\n",
    "    elif arg.lr_anne == 'cosine':\n",
    "        # Use a cosine function to adjust the learning rate\n",
    "        a_lr = (np.cos(np.pi * ep / ep_train) + 1) / 2\n",
    "    elif arg.lr_anne == 'repeat':\n",
    "        # Use a repeated cosine function to adjust the learning rate\n",
    "        partition = [0, 0.15, 0.30, 0.45, 0.6, 0.8, 1.0]\n",
    "        par = int(np.digitize(ep * 1. / ep_train, partition))\n",
    "        T = (partition[par] - partition[par - 1]) * ep_train\n",
    "        t = ep - partition[par - 1] * ep_train\n",
    "        a_lr = 0.5 * (1 + np.cos(np.pi * t / T))\n",
    "        a_lr *= 1 - partition[par - 1]\n",
    "    else:\n",
    "        # Use a constant learning rate\n",
    "        a_lr = 1\n",
    "\n",
    "    # Set the learning rate for all parameter groups in the optimizer\n",
    "    for param_group in optim.param_groups:\n",
    "        param_group['lr'] = max(a_lr, 0.01) * arg.lr\n",
    "\n",
    "    # If bn is True, adjust the momentum of batch normalization layers\n",
    "    if bn:\n",
    "        def fn(m):\n",
    "            if isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d)):\n",
    "                # Set the momentum of batch normalization layers to the current learning rate\n",
    "                m.momentum = min(max(a_lr, 0.01), 0.9)\n",
    "        enc.apply(fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definition of the training_function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ep, loader_train):\n",
    "    \n",
    "    # iterate over the training data loader\n",
    "    #for i, (inL0,outS_Tensor,outS) in enumerate(loader_train):\n",
    "    for i, (img,plug_mask_tensor,plug_mask) in enumerate(loader_train):\n",
    "\n",
    "        # enable GPU if enabled in arguments\n",
    "        if gpu_enabled == True:\n",
    "            img = img.cuda()\n",
    "            plug_mask_tensor = plug_mask_tensor.cuda()\n",
    "\n",
    "        # calculate the iteration count and total iterations for the current epoch\n",
    "        ith = ep * len(loader_train.dataset) // arg.batch_size + i, \\\n",
    "            arg.ep_train * len(loader_train.dataset) // arg.batch_size\n",
    "        \n",
    "        # update learning rate based on the scheduler and current iteration count\n",
    "        adjust_lr(*ith)\n",
    "\n",
    "        # update kp sigma\n",
    "        kper.sigma = min(2.0 * ith[0] / ith[1], 1) * (arg.sigma_kp[1] - arg.sigma_kp[0]) + arg.sigma_kp[0]\n",
    "\n",
    "        # generate key points for the input image\n",
    "        keypL0 = enc(img)\n",
    "\n",
    "        # calculate the concentration loss, which concentrates feature points around the edges of the object\n",
    "        # (not on the object itself due to the lack of object detection)\n",
    "        lossC = None\n",
    "        if arg.concentrate != 0:\n",
    "            lossC = []\n",
    "            for idx_i in range(0, arg.num_keypoint - 1):\n",
    "                for idx_j in range(idx_i + 1, arg.num_keypoint):\n",
    "                    distL = torch.norm(torch.cat(\n",
    "                        ((keypL0[0][:, idx_i] - keypL0[0][:, idx_j]).unsqueeze(1),\n",
    "                        (keypL0[0][:, idx_i + arg.num_keypoint] - keypL0[0][:, idx_j + arg.num_keypoint]).unsqueeze(1)),\n",
    "                        dim=1), dim=1)\n",
    "                    lossC.append(distL.mul(arg.concentrate).exp().mul(keypL0[0][:, idx_i + 2 * arg.num_keypoint] *\n",
    "                                                                    keypL0[0][:, idx_j + 2 * arg.num_keypoint]).mean())\n",
    "            lossC = sum(lossC) / len(lossC)\n",
    "        \n",
    "        # calculate the inside loss, which forces the key points to be within the object boundaries\n",
    "        lossI = None\n",
    "        if arg.inside != 0:\n",
    "            inoutL = plug_mask_tensor.eq(0).float()\n",
    "            inoutL = F.interpolate(inoutL.unsqueeze(1), size=keypL0[1].size()[2:], align_corners=False, mode='bilinear')\n",
    "            lossI = arg.inside * (inoutL.mul(keypL0[1]).mean()) \n",
    "\n",
    "        # set the gradients of all optimizer variables to zero\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # calculate and backpropagate the total loss\n",
    "        sum([l for l in [lossC,lossI] if l is not None]).backward()\n",
    "\n",
    "        # update the optimizer variables\n",
    "        optim.step()\n",
    "\n",
    "        # print the loss for the current epoch\n",
    "        if i == 0:\n",
    "            if arg.concentrate == 0:\n",
    "                tqdm.write('ep: {}, loss_I: {:.5f}  '.format(ep,lossI.item()))\n",
    "            elif arg.inside == 0:\n",
    "                tqdm.write('ep: {}, loss_C: {:.5f}  '.format(ep,lossC.item()))\n",
    "            else:\n",
    "                tqdm.write('ep: {}, loss_C loss_I: {:.5f} {:.5f} '.format(ep,lossC.item(), lossI.item()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(base_dir):\n",
    "    state = {'enc_state_dict': enc.state_dict()}\n",
    "    torch.save(state, os.path.join(base_dir, 'ckpt.pth'))\n",
    "    print('checkpoint saved.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main-function for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train():\n",
    "    if arg.task in ['full']:\n",
    "        # create directory to save data\n",
    "        if not os.path.exists(arg.dir_base):\n",
    "            os.makedirs(arg.dir_base)\n",
    "        # copy the configuration file to the created directory\n",
    "        os.system('cp {} {}'.format(\"cfg/train_real_images.yaml\" ,os.path.join(arg.dir_base, 'servo.yaml')))\n",
    "\n",
    "        # check if grayscale or RGB images are used for training and load the corresponding dataset\n",
    "        if arg.num_input == 1:\n",
    "            print(\"Training with grayscale images\")\n",
    "            ds_train = DataServoStereo(arg,grey=True)\n",
    "        else:\n",
    "            print(\"Training with RGB images\")\n",
    "            ds_train = DataServoStereo(arg,grey=False)\n",
    "\n",
    "        # set parameters for the data loader\n",
    "        data_param = {'pin_memory': False, 'shuffle': True, 'batch_size': arg.batch_size, 'drop_last': True,\n",
    "                      'num_workers': 8, 'worker_init_fn': lambda _: np.random.seed(ord(os.urandom(1)))}\n",
    "        \n",
    "        # create data loader for training dataset\n",
    "        loader_train = loader.DataLoader(ds_train, **data_param)\n",
    "\n",
    "        # set the encoder model to training mode\n",
    "        enc.train()\n",
    "        print('training...')\n",
    "        # train for each epoch\n",
    "        for ep in trange(arg.ep_train):\n",
    "            train(ep, loader_train)\n",
    "\n",
    "        # save the trained model checkpoint\n",
    "        save_checkpoint(arg.dir_base)\n",
    "\n",
    "        # think it is better here to safe the config file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with grayscale images\n",
      "160 training data loaded\n",
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:08<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, loss_C loss_I: 0.27582 0.00192 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [09:35<3:37:11, 566.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 1, loss_C loss_I: 0.00265 0.00155 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/24 [18:53<3:25:50, 561.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 2, loss_C loss_I: 0.00407 0.00139 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 3/24 [28:43<3:21:06, 574.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 3, loss_C loss_I: 0.00518 0.00129 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/24 [38:56<3:15:05, 585.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 4, loss_C loss_I: 0.00100 0.00118 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 5/24 [59:46<4:22:26, 828.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 5, loss_C loss_I: 0.00304 0.00106 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 6/24 [1:15:55<4:23:02, 876.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 6, loss_C loss_I: 0.00069 0.00100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 6/24 [1:21:32<4:04:38, 815.47s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb Cell 21\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Execute \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m main_train()\n",
      "\u001b[1;32m/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb Cell 21\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# train for each epoch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m trange(arg\u001b[39m.\u001b[39mep_train):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     train(ep, loader_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# save the trained model checkpoint\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m save_checkpoint(arg\u001b[39m.\u001b[39mdir_base)\n",
      "\u001b[1;32m/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb Cell 21\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# calculate and backpropagate the total loss\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39msum\u001b[39;49m([l \u001b[39mfor\u001b[39;49;00m l \u001b[39min\u001b[39;49;00m [lossC,lossI] \u001b[39mif\u001b[39;49;00m l \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m])\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39m# update the optimizer variables\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sebastian/025_FundE_Teil2/F-E-Project_Part_2/002_NN_tranieren.ipynb#X26sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m optim\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Execute \n",
    "main_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
