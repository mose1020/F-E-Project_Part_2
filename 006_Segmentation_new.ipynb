{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from train_dataset import img_patch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load and preprocess the images\n",
    "datapath = 'dataset/mini_testdatensatz'\n",
    "datapath = datapath + '/train'\n",
    "im_size= [192,192]\n",
    "\n",
    "\n",
    "images= []\n",
    "\n",
    "filenames_train = os.listdir(datapath)\n",
    "\n",
    "\n",
    "for filename in filenames_train:\n",
    "    img = Image.open(os.path.join(datapath,filename)) # Convert to grayscale\n",
    "    img_resized = img_patch(img, im_size)\n",
    "    img_grey = img_resized.convert('L')  # Resize the image\n",
    "    img_numpy = np.array(img_grey) / 255.0             # Normalize the pixel values\n",
    "    #img_reshape = img_numpy.reshape((im_size[0], im_size[1], 1))  # Add the channel dimension\n",
    "    images.append(img_numpy)\n",
    "\n",
    "\n",
    "\n",
    "# Convert the list of images to a NumPy array\n",
    "images = np.array(images)\n",
    "x_train, x_test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "# Define the input shape\n",
    "input_img = Input(shape=(im_size[0], im_size[1], 1))\n",
    "\n",
    "# Define the encoder layers\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Define the decoder layers\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder model\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# Use the trained autoencoder to segment the input image\n",
    "segmented_img = autoencoder.predict(input_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a function to load and preprocess the images\n",
    "def preprocess_images(datapath, im_size):\n",
    "    images = []\n",
    "    filenames_train = os.listdir(datapath)\n",
    "\n",
    "    for filename in filenames_train:\n",
    "        img = Image.open(os.path.join(datapath, filename)).convert('L')  # Convert to grayscale\n",
    "        img_resized = img.resize(im_size)  # Resize the image\n",
    "        img_numpy = np.array(img_resized, dtype='float32') / 255.0  # Normalize the pixel values\n",
    "        img_reshape = img_numpy.reshape((*im_size, 1))  # Add the channel dimension\n",
    "        images.append(img_reshape)\n",
    "\n",
    "    # Convert the list of images to a NumPy array\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "# Load and preprocess the training and testing images\n",
    "datapath = 'dataset/mini_testdatensatz/train'\n",
    "im_size = [192, 192]\n",
    "x_train = preprocess_images(datapath, im_size)\n",
    "datapath = 'dataset/mini_testdatensatz/test'\n",
    "x_test = preprocess_images(datapath, im_size)\n",
    "\n",
    "# Define the input shape\n",
    "input_img = Input(shape=(*im_size, 1))\n",
    "\n",
    "# Define the encoder layers\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Define the decoder layers\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "\n",
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Train the autoencoder model\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained autoencoder to segment a new image\n",
    "new_image_path = 'path/to/new/image.jpg'\n",
    "new_img = Image.open(new_image_path).convert('L')\n",
    "new_img_resized = new_img.resize(im_size)\n",
    "new_img_numpy = np.array(new_img_resized, dtype='float32') / 255.0\n",
    "new_img_reshape = new_img_numpy.reshape((*im_size, 1))\n",
    "segmented_img = autoencoder.predict(np.array([new_img_reshape]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
